"""
ğŸ§ª ALCHEM_PropBtn ç®€åŒ–å†…å­˜ç®¡ç†æ¨¡å—

ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼šåˆ†å­æ•°æ®çš„å­˜å‚¨å’ŒæŸ¥è¯¢
åˆ é™¤äº†è¿‡åº¦è®¾è®¡çš„åˆ†æåŠŸèƒ½å’Œæœªä½¿ç”¨çš„æ´»è·ƒèŠ‚ç‚¹æœºåˆ¶
"""

import os
import time
import threading
from typing import Dict, Any, Optional
import folder_paths

# ä½¿ç”¨ç»Ÿä¸€çš„ALCHEMæ—¥å¿—ç³»ç»Ÿ
from .logging_config import get_memory_logger

# åˆå§‹åŒ–ç»Ÿä¸€Logger
logger = get_memory_logger()

# å°è¯•å¯¼å…¥WebSocketé€šçŸ¥åŠŸèƒ½
try:
    from .websocket_server import notify_molecular_update, notify_molecular_edit, notify_molecular_delete
    WEBSOCKET_NOTIFY_AVAILABLE = True
    logger.success("WebSocketé€šçŸ¥åŠŸèƒ½åŠ è½½æˆåŠŸ")
except ImportError as e:
    WEBSOCKET_NOTIFY_AVAILABLE = False
    logger.warning(f"WebSocketé€šçŸ¥åŠŸèƒ½ä¸å¯ç”¨ - {e}")
    
    # åˆ›å»ºç©ºçš„å¼‚æ­¥é€šçŸ¥å‡½æ•°ï¼Œé¿å…ä»£ç æŠ¥é”™
    async def notify_molecular_update(node_id, data):
        pass
    async def notify_molecular_edit(node_id, data):
        pass
    async def notify_molecular_delete(node_id):
        pass

# å…¨å±€åˆ†å­æ•°æ®ç¼“å­˜ - ç®€åŒ–ç‰ˆæœ¬
MOLECULAR_DATA_CACHE: Dict[str, Dict[str, Any]] = {}

# ğŸ”‘ å°†è¢«ç§»é™¤ï¼šå…¨å±€æ´»è·ƒtab_idï¼ˆå·²è¢«å‰ç«¯ä¼ å‚æ›¿ä»£ï¼‰
# ACTIVE_TAB_ID: Optional[str] = None  # å·²åºŸå¼ƒï¼Œä½¿ç”¨å‰ç«¯ä¼ å…¥çš„_alchem_node_id

# çº¿ç¨‹é”ï¼Œç¡®ä¿ç¼“å­˜æ“ä½œçš„çº¿ç¨‹å®‰å…¨
CACHE_LOCK = threading.Lock()


class MolecularDataManager:
    """
    ğŸ§ª ç®€åŒ–çš„åˆ†å­æ•°æ®å†…å­˜ç®¡ç†å™¨
    
    ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å­˜å‚¨åˆ†å­æ•°æ®åˆ°å†…å­˜ç¼“å­˜
    2. ä»ç¼“å­˜è·å–åˆ†å­æ•°æ®  
    3. ç¼“å­˜çŠ¶æ€æŸ¥è¯¢
    4. ç¼“å­˜æ¸…ç†ï¼ˆè°ƒè¯•ç”¨ï¼‰
    """
    
    @classmethod
    def store_molecular_data(cls, node_id: str, filename: str, folder: str = "molecules", 
                           content: str = None) -> Optional[Dict[str, Any]]:
        """
        å­˜å‚¨åˆ†å­æ•°æ®åˆ°å†…å­˜ç¼“å­˜
        
        Args:
            node_id: ComfyUIèŠ‚ç‚¹çš„å”¯ä¸€ID
            filename: åˆ†å­æ–‡ä»¶å
            folder: å­˜å‚¨æ–‡ä»¶å¤¹ï¼ˆé»˜è®¤moleculesï¼‰
            content: åˆ†å­æ–‡ä»¶å†…å®¹
            
        Returns:
            å­˜å‚¨çš„æ•°æ®å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        with CACHE_LOCK:
            try:
                # éªŒè¯å¿…éœ€å‚æ•°
                if not node_id or not filename:
                    logger.error("å­˜å‚¨å¤±è´¥ï¼šèŠ‚ç‚¹IDå’Œæ–‡ä»¶åä¸èƒ½ä¸ºç©º")
                    return None
                
                if not content:
                    logger.error("å­˜å‚¨å¤±è´¥ï¼šæ–‡ä»¶å†…å®¹ä¸èƒ½ä¸ºç©º")
                    return None
                
                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè¿½è¸ªèŠ‚ç‚¹IDæ ¼å¼
                logger.molecular(f"[DEBUG] å­˜å‚¨åˆ†å­æ•°æ®å¼€å§‹:")
                logger.molecular(f"  - åŸå§‹node_id: '{node_id}'")
                logger.molecular(f"  - node_idç±»å‹: {type(node_id)}")
                logger.molecular(f"  - node_idé•¿åº¦: {len(node_id)}")
                logger.molecular(f"  - æ–‡ä»¶å: {filename}")
                
                # æ£€æµ‹åŸºæœ¬æ ¼å¼ä¿¡æ¯
                file_format = cls._detect_format(filename)
                
                # ğŸ”‘ æå–tab_idï¼ˆå…³é”®æ–°å¢ï¼‰
                tab_id = None
                if "_node_" in node_id:
                    tab_id = node_id.split("_node_")[0]  # ä¾‹å¦‚: "workflow_fl40l5"
                    logger.molecular(f"[DEBUG] è§£ænode_id:")
                    logger.molecular(f"  - æå–çš„tab_id: '{tab_id}'")
                    logger.molecular(f"  - åˆ†å‰²åçš„èŠ‚ç‚¹éƒ¨åˆ†: '{node_id.split('_node_')[1] if len(node_id.split('_node_')) > 1 else 'None'}")
                else:
                    logger.warning(f"[DEBUG] node_idæ ¼å¼å¼‚å¸¸ï¼ŒæœªåŒ…å«'_node_': '{node_id}'")
                
                # åˆ›å»ºå­˜å‚¨æ•°æ®ç»“æ„
                molecular_data = {
                    "node_id": node_id,
                    "filename": filename,
                    "folder": folder,
                    "content": content,
                    "format": file_format,
                    "format_name": cls._get_format_name(file_format),
                    "tab_id": tab_id,  # ğŸ”‘ æ–°å¢ï¼šTabæ ‡è¯†
                    
                    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                    "file_stats": {
                        "size": len(content),
                        "lines": content.count('\n') + 1
                    },
                    
                    # ç®€å•çš„åŸå­è®¡æ•°ï¼ˆä¸åšå¤æ‚åˆ†æï¼‰
                    "atoms": cls._simple_atom_count(content, file_format),
                    
                    # ç¼“å­˜ç®¡ç†ä¿¡æ¯
                    "cached_at": time.time(),
                    "last_accessed": time.time(),
                    "access_count": 0
                }
                
                # ä¿å­˜åˆ°å…¨å±€ç¼“å­˜
                MOLECULAR_DATA_CACHE[node_id] = molecular_data
                
                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šéªŒè¯å­˜å‚¨
                logger.molecular(f"[DEBUG] æ•°æ®å·²å­˜å‚¨åˆ°ç¼“å­˜:")
                logger.molecular(f"  - ç¼“å­˜key: '{node_id}'")
                logger.molecular(f"  - å½“å‰ç¼“å­˜ä¸­çš„æ‰€æœ‰keys: {list(MOLECULAR_DATA_CACHE.keys())}")
                logger.molecular(f"  - ç¼“å­˜å¤§å°: {len(MOLECULAR_DATA_CACHE)}")
                
                # ğŸ”‘ ä¿®å¤ï¼šä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿæ—¶ä¼ é€’èŠ‚ç‚¹IDï¼Œé¿å…é‡åæ–‡ä»¶è¦†ç›–
                try:
                    cls._save_to_filesystem(filename, folder, content, node_id)
                except Exception as e:
                    logger.warning(f"æ–‡ä»¶ç³»ç»Ÿä¿å­˜å¤±è´¥: {e}")
                
                logger.success(f"[DEBUG] åˆ†å­æ•°æ®å­˜å‚¨æˆåŠŸ: {filename} -> èŠ‚ç‚¹ {node_id}")
                
                # ğŸš€ å‘é€WebSocketé€šçŸ¥ï¼ˆæ”¹è¿›çš„å®‰å…¨è°ƒç”¨ï¼‰
                if WEBSOCKET_NOTIFY_AVAILABLE:
                    try:
                        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¼‚æ­¥é€šçŸ¥
                        import asyncio
                        import concurrent.futures
                        import threading
                        
                        def run_async_notify():
                            """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥é€šçŸ¥"""
                            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                # è¿è¡Œå¼‚æ­¥å‡½æ•°
                                loop.run_until_complete(notify_molecular_update(node_id, molecular_data))
                                logger.network(f"[DEBUG] WebSocketæ›´æ–°é€šçŸ¥å‘é€æˆåŠŸ")
                            finally:
                                loop.close()
                        
                        # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œ
                        thread = threading.Thread(target=run_async_notify, daemon=True)
                        thread.start()
                        
                        logger.network(f"[DEBUG] WebSocketæ›´æ–°é€šçŸ¥è¯¦æƒ…:")
                        logger.network(f"  - èŠ‚ç‚¹ID: '{node_id}'")
                        logger.network(f"  - é€šçŸ¥ç±»å‹: 'update'")
                        logger.network(f"  - æ–‡ä»¶å: {molecular_data.get('filename')}")
                        
                    except Exception as e:
                        logger.error(f"WebSocketé€šçŸ¥å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                
                return molecular_data
                
            except Exception as e:
                logger.error(f"å­˜å‚¨åˆ†å­æ•°æ®æ—¶å‡ºé”™: {e}")
                return None
    
    @classmethod
    def get_molecular_data(cls, node_id: str) -> Optional[Dict[str, Any]]:
        """
        ä»ç¼“å­˜è·å–åˆ†å­æ•°æ®
        
        Args:
            node_id: èŠ‚ç‚¹ID
            
        Returns:
            åˆ†å­æ•°æ®å­—å…¸ï¼Œä¸å­˜åœ¨è¿”å›None
        """
        with CACHE_LOCK:
            try:
                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè¿½è¸ªæ•°æ®è·å–
                logger.debug(f"[DEBUG] è·å–åˆ†å­æ•°æ®:")
                logger.debug(f"  - è¯·æ±‚çš„node_id: '{node_id}'")
                logger.debug(f"  - ç¼“å­˜ä¸­çš„keys: {list(MOLECULAR_DATA_CACHE.keys())}")
                
                if node_id in MOLECULAR_DATA_CACHE:
                    data = MOLECULAR_DATA_CACHE[node_id]
                    
                    # æ›´æ–°è®¿é—®ç»Ÿè®¡
                    data["last_accessed"] = time.time()
                    data["access_count"] = data.get("access_count", 0) + 1
                    
                    logger.debug(f"[DEBUG] æ‰¾åˆ°æ•°æ®:")
                    logger.debug(f"  - æ–‡ä»¶å: {data.get('filename')}")
                    logger.debug(f"  - tab_id: {data.get('tab_id')}")
                    logger.debug(f"  - è®¿é—®æ¬¡æ•°: {data.get('access_count')}")
                    return data
                else:
                    logger.warning(f"[DEBUG] èŠ‚ç‚¹ '{node_id}' çš„æ•°æ®ä¸å­˜åœ¨!")
                    logger.warning(f"  - å¯ç”¨çš„keys: {list(MOLECULAR_DATA_CACHE.keys())}")
                    return None
                    
            except Exception as e:
                logger.error(f"è·å–åˆ†å­æ•°æ®æ—¶å‡ºé”™: {e}")
                return None
    
    @classmethod
    def get_cache_status(cls) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜çŠ¶æ€ç»Ÿè®¡
        
        Returns:
            ç¼“å­˜çŠ¶æ€å­—å…¸
        """
        with CACHE_LOCK:
            try:
                total_nodes = len(MOLECULAR_DATA_CACHE)
                total_cache_size = sum(len(data.get("content", "")) for data in MOLECULAR_DATA_CACHE.values())
                
                # æ„å»ºèŠ‚ç‚¹åˆ—è¡¨ï¼ˆå¢åŠ tab_idä¿¡æ¯ï¼‰
                nodes = []
                for node_id, data in MOLECULAR_DATA_CACHE.items():
                    nodes.append({
                        "node_id": node_id,
                        "filename": data.get("filename"),
                        "format": data.get("format"),
                        "atoms": data.get("atoms", 0),
                        "tab_id": data.get("tab_id"),  # ğŸ”‘ æ–°å¢ï¼šTabæ ‡è¯†
                        "cached_at": data.get("cached_at"),
                        "access_count": data.get("access_count", 0)
                    })
                
                # æŒ‰è®¿é—®æ—¶é—´æ’åº
                nodes.sort(key=lambda x: x.get("access_count", 0), reverse=True)
                
                return {
                    "total_nodes": total_nodes,
                    "total_cache_size": total_cache_size,
                    "nodes": nodes,
                    "status": "active" if total_nodes > 0 else "empty"
                }
                
            except Exception as e:
                logger.error(f"è·å–ç¼“å­˜çŠ¶æ€æ—¶å‡ºé”™: {e}")
                return {"error": str(e)}
    
    @classmethod
    def edit_molecular_data(cls, node_id: str, edit_type: str, **kwargs) -> Optional[Dict[str, Any]]:
        """
        ç¼–è¾‘åˆ†å­æ•°æ®ï¼ˆç®€å•ç‰ˆæœ¬ï¼Œç”¨äºæ¦‚å¿µéªŒè¯ï¼‰
        
        Args:
            node_id: èŠ‚ç‚¹ID
            edit_type: ç¼–è¾‘ç±»å‹ï¼ˆ'remove_last_atom'ï¼‰
            **kwargs: ç¼–è¾‘å‚æ•°
            
        Returns:
            ç¼–è¾‘åçš„æ•°æ®å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        with CACHE_LOCK:
            try:
                # ğŸ”§ è°ƒè¯•ï¼šæ˜¾ç¤ºç¼“å­˜ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹ID
                logger.debug(f"[DEBUG] ç¼–è¾‘åˆ†å­æ•°æ®:")
                logger.debug(f"  - ç›®æ ‡node_id: '{node_id}'")
                logger.debug(f"  - ç¼–è¾‘ç±»å‹: {edit_type}")
                logger.debug(f"  - ç¼“å­˜ä¸­çš„èŠ‚ç‚¹IDåˆ—è¡¨: {list(MOLECULAR_DATA_CACHE.keys())}")
                
                if node_id not in MOLECULAR_DATA_CACHE:
                    logger.warning(f"èŠ‚ç‚¹ {node_id} çš„æ•°æ®ä¸å­˜åœ¨ï¼Œæ— æ³•ç¼–è¾‘")
                    logger.warning(f"å¯ç”¨çš„èŠ‚ç‚¹ID: {list(MOLECULAR_DATA_CACHE.keys())}")
                    return None
                
                molecular_data = MOLECULAR_DATA_CACHE[node_id]
                original_content = molecular_data.get("content", "")
                
                if edit_type == "remove_last_atom":
                    # ğŸ§ª ç®€å•ç¼–è¾‘ï¼šåˆ é™¤PDBä¸­æœ€åä¸€ä¸ªåŸå­
                    logger.molecular(f"å¼€å§‹ç¼–è¾‘: {edit_type}, åŸå§‹å†…å®¹é•¿åº¦: {len(original_content)}")
                    edited_content = cls._remove_last_atom_from_pdb(original_content)
                    logger.molecular(f"ç¼–è¾‘å®Œæˆ: æ–°å†…å®¹é•¿åº¦: {len(edited_content)}")
                    
                    if edited_content != original_content:
                        # æ›´æ–°æ•°æ®
                        molecular_data["content"] = edited_content
                        molecular_data["atoms"] = cls._simple_atom_count(edited_content, molecular_data.get("format", ""))
                        molecular_data["last_edited"] = time.time()
                        molecular_data["edit_history"] = molecular_data.get("edit_history", [])
                        molecular_data["edit_history"].append({
                            "type": edit_type,
                            "timestamp": time.time(),
                            "description": "åˆ é™¤æœ€åä¸€ä¸ªåŸå­"
                        })
                        
                        logger.success(f"ç¼–è¾‘æˆåŠŸ: èŠ‚ç‚¹ {node_id} åˆ é™¤æœ€åä¸€ä¸ªåŸå­")
                        
                        # ğŸš€ å‘é€WebSocketç¼–è¾‘é€šçŸ¥ï¼ˆæ”¹è¿›çš„å®‰å…¨è°ƒç”¨ï¼‰
                        if WEBSOCKET_NOTIFY_AVAILABLE:
                            try:
                                edit_info = {
                                    "edit_type": edit_type,
                                    "description": "åˆ é™¤æœ€åä¸€ä¸ªåŸå­",
                                    "atoms_count": molecular_data["atoms"],
                                    "timestamp": time.time()
                                }
                                
                                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¼‚æ­¥é€šçŸ¥
                                import asyncio
                                import threading
                                
                                def run_async_notify():
                                    """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥é€šçŸ¥"""
                                    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                                    loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(loop)
                                    try:
                                        # è¿è¡Œå¼‚æ­¥å‡½æ•°
                                        loop.run_until_complete(notify_molecular_edit(node_id, edit_info))
                                        logger.network(f"[DEBUG] WebSocketç¼–è¾‘é€šçŸ¥å‘é€æˆåŠŸ")
                                    finally:
                                        loop.close()
                                
                                # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œ
                                thread = threading.Thread(target=run_async_notify, daemon=True)
                                thread.start()
                                
                                logger.network(f"[DEBUG] WebSocketç¼–è¾‘é€šçŸ¥è¯¦æƒ…:")
                                logger.network(f"  - èŠ‚ç‚¹ID: '{node_id}'")
                                logger.network(f"  - é€šçŸ¥ç±»å‹: 'edit'")
                                logger.network(f"  - ç¼–è¾‘ç±»å‹: {edit_type}")
                                
                            except Exception as e:
                                logger.error(f"WebSocketç¼–è¾‘é€šçŸ¥å¤±è´¥: {e}")
                                import traceback
                                traceback.print_exc()
                        
                        return molecular_data
                    else:
                        logger.warning(f"ç¼–è¾‘æ— æ•ˆæœ: èŠ‚ç‚¹ {node_id}")
                        return None
                        
                else:
                    logger.warning(f"ä¸æ”¯æŒçš„ç¼–è¾‘ç±»å‹: {edit_type}")
                    return None
                    
            except Exception as e:
                logger.error(f"ç¼–è¾‘åˆ†å­æ•°æ®æ—¶å‡ºé”™: {e}")
                return None
    
    @classmethod
    def clear_cache(cls, node_id: str = None) -> bool:
        """
        æ¸…é™¤ç¼“å­˜æ•°æ®ï¼ˆè°ƒè¯•ç”¨ï¼‰
        
        Args:
            node_id: æŒ‡å®šèŠ‚ç‚¹IDï¼ŒNoneåˆ™æ¸…é™¤æ‰€æœ‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        with CACHE_LOCK:
            try:
                if node_id:
                    if node_id in MOLECULAR_DATA_CACHE:
                        del MOLECULAR_DATA_CACHE[node_id]
                        logger.storage(f"æ¸…é™¤èŠ‚ç‚¹ {node_id} çš„ç¼“å­˜")
                        return True
                    else:
                        logger.warning(f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨")
                        return False
                else:
                    MOLECULAR_DATA_CACHE.clear()
                    logger.storage("æ¸…é™¤æ‰€æœ‰ç¼“å­˜")
                    return True
                    
            except Exception as e:
                logger.error(f"æ¸…é™¤ç¼“å­˜æ—¶å‡ºé”™: {e}")
                return False
    
    # ====================================================================================================
    # ç®€åŒ–çš„è¾…åŠ©å‡½æ•° - åªä¿ç•™å¿…éœ€çš„
    # ====================================================================================================
    
    @staticmethod
    def _detect_format(filename: str) -> str:
        """ç®€å•çš„æ ¼å¼æ£€æµ‹"""
        ext = filename.lower().split('.')[-1] if '.' in filename else ""
        return ext if ext in ['pdb', 'mol', 'sdf', 'xyz', 'mol2', 'cif', 'gro'] else "unknown"
    
    @staticmethod
    def _get_format_name(file_format: str) -> str:
        """è·å–æ ¼å¼å…¨å"""
        format_names = {
            "pdb": "Protein Data Bank",
            "mol": "MDL Molfile", 
            "sdf": "Structure Data File",
            "xyz": "XYZ Format",
            "mol2": "Tripos MOL2",
            "cif": "Crystallographic Information File",
            "gro": "GROMACS Format"
        }
        return format_names.get(file_format, "Unknown Format")
    
    @staticmethod
    def _simple_atom_count(content: str, file_format: str) -> int:
        """ç®€å•çš„åŸå­è®¡æ•°ï¼ˆä¸åšå¤æ‚åˆ†æï¼‰"""
        try:
            if file_format == "pdb":
                return content.count("ATOM") + content.count("HETATM")
            elif file_format in ["mol", "sdf"]:
                lines = content.split('\n')
                if len(lines) > 3:
                    counts_line = lines[3].split()
                    return int(counts_line[0]) if counts_line else 0
            elif file_format == "xyz":
                lines = content.split('\n')
                return int(lines[0]) if lines and lines[0].isdigit() else 0
            else:
                # å…¶ä»–æ ¼å¼çš„ç®€å•ä¼°ç®—
                return len([line for line in content.split('\n') if line.strip() and not line.startswith('#')])
        except:
            return 0
    
    @staticmethod
    def _save_to_filesystem(filename: str, folder: str, content: str, node_id: str = None):
        """
        ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰ - æ·»åŠ èŠ‚ç‚¹IDé¿å…é‡åæ–‡ä»¶å†²çª
        
        Args:
            filename: åŸå§‹æ–‡ä»¶å
            folder: å­˜å‚¨æ–‡ä»¶å¤¹
            content: æ–‡ä»¶å†…å®¹
            node_id: èŠ‚ç‚¹IDï¼Œç”¨äºç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        """
        try:
            # è·å–ComfyUIçš„inputç›®å½•
            input_dir = folder_paths.get_input_directory()
            target_dir = os.path.join(input_dir, folder)
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(target_dir, exist_ok=True)
            
            # ğŸ”‘ ä¿®å¤ï¼šä¸ºé‡åæ–‡ä»¶æ·»åŠ èŠ‚ç‚¹IDåç¼€ï¼Œé¿å…è¦†ç›–
            if node_id:
                # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
                name_parts = filename.rsplit('.', 1)
                if len(name_parts) == 2:
                    name, ext = name_parts
                    # æå–èŠ‚ç‚¹æ•°å­—éƒ¨åˆ†ä½œä¸ºåç¼€
                    node_suffix = node_id.split('_node_')[-1] if '_node_' in node_id else node_id[-3:]
                    unique_filename = f"{name}_node{node_suffix}.{ext}"
                else:
                    # æ²¡æœ‰æ‰©å±•åçš„æƒ…å†µ
                    node_suffix = node_id.split('_node_')[-1] if '_node_' in node_id else node_id[-3:]
                    unique_filename = f"{filename}_node{node_suffix}"
                
                logger.storage(f"[DEBUG] æ–‡ä»¶é‡åä¿æŠ¤:")
                logger.storage(f"  - åŸå§‹æ–‡ä»¶å: {filename}")
                logger.storage(f"  - èŠ‚ç‚¹ID: {node_id}")
                logger.storage(f"  - å”¯ä¸€æ–‡ä»¶å: {unique_filename}")
            else:
                unique_filename = filename
            
            # å†™å…¥æ–‡ä»¶ï¼ˆä½¿ç”¨å”¯ä¸€æ–‡ä»¶åï¼‰
            file_path = os.path.join(target_dir, unique_filename)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
            logger.storage(f"æ–‡ä»¶å·²ä¿å­˜: {file_path}")
            
        except Exception as e:
            logger.warning(f"æ–‡ä»¶ç³»ç»Ÿä¿å­˜å¤±è´¥: {e}")
            raise
    
    @staticmethod
    def _remove_last_atom_from_pdb(content: str) -> str:
        """
        ä»PDBå†…å®¹ä¸­åˆ é™¤æœ€åä¸€ä¸ªåŸå­ï¼ˆç®€å•ç¼–è¾‘åŠŸèƒ½ï¼‰
        
        Args:
            content: PDBæ–‡ä»¶å†…å®¹
            
        Returns:
            ç¼–è¾‘åçš„PDBå†…å®¹
        """
        try:
            lines = content.split('\n')
            logger.molecular(f"è§£æPDB: æ€»è¡Œæ•° {len(lines)}")
            
            # æ‰¾åˆ°æ‰€æœ‰åŸå­è¡Œçš„ç´¢å¼•
            atom_line_indices = []
            for i, line in enumerate(lines):
                if line.startswith('ATOM') or line.startswith('HETATM'):
                    atom_line_indices.append(i)
            
            logger.molecular(f"æ‰¾åˆ° {len(atom_line_indices)} ä¸ªåŸå­è¡Œ")
            
            if not atom_line_indices:
                logger.warning(f"æ²¡æœ‰æ‰¾åˆ°ATOMæˆ–HETATMè¡Œï¼Œæ— æ³•åˆ é™¤åŸå­")
                return content
            
            # åˆ é™¤æœ€åä¸€ä¸ªåŸå­è¡Œ
            last_atom_index = atom_line_indices[-1]
            removed_line = lines[last_atom_index]
            logger.molecular(f"åˆ é™¤ç¬¬ {last_atom_index+1} è¡ŒåŸå­: {removed_line[:50]}...")
            
            # åˆ›å»ºæ–°çš„è¡Œåˆ—è¡¨ï¼Œè·³è¿‡æœ€åä¸€ä¸ªåŸå­è¡Œ
            result_lines = []
            for i, line in enumerate(lines):
                if i != last_atom_index:
                    result_lines.append(line)
            
            result_content = '\n'.join(result_lines)
            logger.molecular(f"ç¼–è¾‘å®Œæˆ: {len(lines)} â†’ {len(result_lines)} è¡Œ")
            
            return result_content
            
        except Exception as e:
            logger.error(f"åˆ é™¤åŸå­å¤±è´¥: {e}")
            return content  # è¿”å›åŸå§‹å†…å®¹
    


# ====================================================================================================
# ä¾¿æ·å…¨å±€å‡½æ•° - ç®€åŒ–ç‰ˆæœ¬
# ====================================================================================================

def store_molecular_data(node_id: str, filename: str, folder: str = "molecules", content: str = None):
    """ä¾¿æ·å‡½æ•° - å­˜å‚¨åˆ†å­æ•°æ®"""
    return MolecularDataManager.store_molecular_data(node_id, filename, folder, content)

def get_molecular_data(node_id: str):
    """ä¾¿æ·å‡½æ•° - è·å–åˆ†å­æ•°æ®"""
    return MolecularDataManager.get_molecular_data(node_id)

def get_cache_status():
    """ä¾¿æ·å‡½æ•° - è·å–ç¼“å­˜çŠ¶æ€"""
    return MolecularDataManager.get_cache_status()

def clear_cache(node_id: str = None):
    """ä¾¿æ·å‡½æ•° - æ¸…é™¤ç¼“å­˜"""
    return MolecularDataManager.clear_cache(node_id)

def edit_molecular_data(node_id: str, edit_type: str, **kwargs):
    """ä¾¿æ·å‡½æ•° - ç¼–è¾‘åˆ†å­æ•°æ®"""
    return MolecularDataManager.edit_molecular_data(node_id, edit_type, **kwargs)


# ====================================================================================================
# ğŸ”‘ Active Tab ID ç®¡ç†åŠŸèƒ½
# ====================================================================================================

def update_active_tab_id(tab_id: str):
    """
    [å·²åºŸå¼ƒ] æ›´æ–°æ´»è·ƒçš„tab_id
    
    ç°åœ¨ä½¿ç”¨å‰ç«¯ä¼ å…¥çš„_alchem_node_idï¼Œä¸å†éœ€è¦å…¨å±€çŠ¶æ€
    """
    logger.debug(f"ğŸ”§ update_active_tab_idå·²åºŸå¼ƒï¼Œä¼ å…¥çš„tab_id: {tab_id} å°†è¢«å¿½ç•¥")
    pass

def get_active_tab_id() -> Optional[str]:
    """
    [å·²åºŸå¼ƒ] è·å–å½“å‰æ´»è·ƒçš„tab_id
    
    ç°åœ¨ä½¿ç”¨å‰ç«¯ä¼ å…¥çš„_alchem_node_idï¼Œä¸å†éœ€è¦å…¨å±€çŠ¶æ€
    """
    logger.debug(f"ğŸ”§ get_active_tab_idå·²åºŸå¼ƒï¼Œè¿”å›None")
    return None

def extract_tab_id_from_node_id(node_id: str) -> Optional[str]:
    """
    ä»èŠ‚ç‚¹IDä¸­æå–tab_id
    
    Args:
        node_id: æ ¼å¼å¦‚ "workflow_nv6wm_node_6"
        
    Returns:
        æå–çš„tab_idï¼Œå¦‚ "workflow_nv6wm"
    """
    if '_node_' in node_id:
        return node_id.split('_node_')[0]
    return None