#!/usr/bin/env python3
"""
ğŸ§ª Tabæ„ŸçŸ¥å†…å­˜ç®¡ç†è°ƒè¯•è„šæœ¬

ç”¨äºæµ‹è¯•æ–°çš„tab_idæœºåˆ¶å’Œå†…å­˜ç®¡ç†æ”¹è¿›
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_tab_aware_memory():
    """æµ‹è¯•tabæ„ŸçŸ¥çš„å†…å­˜ç®¡ç†"""
    print("ğŸ§ª Tabæ„ŸçŸ¥å†…å­˜ç®¡ç†æµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    try:
        # å¯¼å…¥å¿…è¦æ¨¡å—
        from backend.memory import store_molecular_data, get_molecular_data, get_cache_status, clear_cache
        from backend.molecular_utils import get_molecular_content
        
        # æ¸…ç†ç¼“å­˜
        clear_cache()
        print("ğŸ§¹ æ¸…ç†ç¼“å­˜å®Œæˆ")
        
        # æ¨¡æ‹ŸPDBæ•°æ®
        sample_pdb = """HEADER    TEST MOLECULE
COMPND    TEST
ATOM      1  C1  TEST A   1       0.000   1.000   0.000  1.00  0.00           C
ATOM      2  C2  TEST A   1       1.000   0.000   0.000  1.00  0.00           C
ATOM      3  H1  TEST A   1       0.500   1.500   0.000  1.00  0.00           H
ATOM      4  H2  TEST A   1       1.500  -0.500   0.000  1.00  0.00           H
END"""
        
        print("\nğŸ¯ æ­¥éª¤1: æµ‹è¯•ç®€åŒ–çš„node_idæ ¼å¼")
        print("-" * 40)
        
        # æµ‹è¯•ä¸åŒçš„èŠ‚ç‚¹IDæ ¼å¼
        test_cases = [
            ("workflow_abc12_node_23", "test_molecule1.pdb"),
            ("workflow_def34_node_45", "test_molecule2.pdb"),
            ("workflow_abc12_node_67", "processed_molecule1.pdb"),  # åŒtabä¸åŒèŠ‚ç‚¹
        ]
        
        for node_id, filename in test_cases:
            print(f"\nğŸ“ å­˜å‚¨æ•°æ®: {node_id} -> {filename}")
            
            result = store_molecular_data(
                node_id=node_id,
                filename=filename,
                folder="molecules",
                content=sample_pdb
            )
            
            if result:
                print(f"âœ… å­˜å‚¨æˆåŠŸ:")
                print(f"   èŠ‚ç‚¹ID: {result['node_id']}")
                print(f"   æ–‡ä»¶å: {result['filename']}")
                print(f"   tab_id: {result['tab_id']}")
                print(f"   åŸå­æ•°: {result['atoms']}")
            else:
                print(f"âŒ å­˜å‚¨å¤±è´¥")
        
        print("\nğŸ¯ æ­¥éª¤2: æŸ¥çœ‹ç¼“å­˜çŠ¶æ€")
        print("-" * 40)
        
        cache_status = get_cache_status()
        print(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {cache_status['total_nodes']}")
        print(f"   æ€»ç¼“å­˜å¤§å°: {cache_status['total_cache_size']} å­—ç¬¦")
        
        print(f"\nğŸ“‹ èŠ‚ç‚¹åˆ—è¡¨:")
        for node in cache_status['nodes']:
            print(f"   {node['node_id']} | {node['filename']} | tab: {node['tab_id']}")
        
        print("\nğŸ¯ æ­¥éª¤3: æµ‹è¯•tabæ„ŸçŸ¥çš„æ•°æ®è·å–")
        print("-" * 40)
        
        # æµ‹è¯•ä¸åŒåœºæ™¯çš„æ•°æ®è·å–
        test_queries = [
            ("test_molecule1.pdb", "workflow_abc12_node_99"),  # åŒtabä¸åŒèŠ‚ç‚¹ï¼Œåº”è¯¥æ‰¾åˆ°
            ("test_molecule2.pdb", "workflow_def34_node_88"),  # ä¸åŒtabï¼Œåº”è¯¥æ‰¾åˆ°å¯¹åº”çš„
            ("processed_molecule1.pdb", "workflow_abc12_node_77"),  # åŒtabå¤„ç†ç»“æœ
            ("nonexistent.pdb", "workflow_abc12_node_66"),  # ä¸å­˜åœ¨çš„æ–‡ä»¶
        ]
        
        for filename, query_node_id in test_queries:
            print(f"\nğŸ” æŸ¥è¯¢: {filename} (èŠ‚ç‚¹: {query_node_id})")
            
            content, metadata = get_molecular_content(
                input_value=filename,
                node_id=query_node_id,
                fallback_to_file=False  # åªæµ‹è¯•å†…å­˜
            )
            
            if metadata['success']:
                print(f"âœ… æŸ¥è¯¢æˆåŠŸ:")
                print(f"   æ¥æº: {metadata['source']}")
                print(f"   æºèŠ‚ç‚¹: {metadata.get('source_node_id', 'N/A')}")
                print(f"   tab_id: {metadata.get('tab_id', 'N/A')}")
                print(f"   å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            else:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {metadata.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        print("\nğŸ¯ æ­¥éª¤4: æµ‹è¯•ä¸­é—´å¤„ç†èŠ‚ç‚¹åœºæ™¯")
        print("-" * 40)
        
        # æ¨¡æ‹Ÿä¸­é—´å¤„ç†èŠ‚ç‚¹çš„å·¥ä½œæµ
        print("ğŸ“ æ¨¡æ‹Ÿå·¥ä½œæµ: upload -> process1 -> process2")
        
        # æ­¥éª¤4.1: æ¨¡æ‹Ÿä»process1èŠ‚ç‚¹è·å–æ•°æ®å¹¶å¤„ç†
        process1_node_id = "workflow_abc12_node_100"
        
        print(f"\nğŸ”§ Process1èŠ‚ç‚¹ ({process1_node_id}) è·å–æ•°æ®:")
        content, metadata = get_molecular_content(
            input_value="test_molecule1.pdb",
            node_id=process1_node_id,
            fallback_to_file=False
        )
        
        if metadata['success']:
            print(f"âœ… Process1è·å–æˆåŠŸ")
            
            # æ¨¡æ‹Ÿå¤„ç†ï¼šåˆ é™¤æ°¢åŸå­
            lines = content.split('\n')
            processed_lines = [line for line in lines if not (line.startswith('ATOM') and 'H' in line)]
            processed_content = '\n'.join(processed_lines)
            
            # å­˜å‚¨å¤„ç†ç»“æœ
            result = store_molecular_data(
                node_id=process1_node_id,
                filename="no_hydrogens.pdb",
                folder="molecules", 
                content=processed_content
            )
            
            if result:
                print(f"âœ… Process1å¤„ç†ç»“æœå·²å­˜å‚¨:")
                print(f"   è¾“å‡ºæ–‡ä»¶: {result['filename']}")
                print(f"   åŸå­æ•°: {result['atoms']} (åˆ é™¤æ°¢åŸå­)")
                
                # æ­¥éª¤4.2: æ¨¡æ‹Ÿprocess2èŠ‚ç‚¹è·å–process1çš„ç»“æœ
                process2_node_id = "workflow_abc12_node_101"
                
                print(f"\nğŸ”§ Process2èŠ‚ç‚¹ ({process2_node_id}) è·å–Process1ç»“æœ:")
                content2, metadata2 = get_molecular_content(
                    input_value="no_hydrogens.pdb",
                    node_id=process2_node_id,
                    fallback_to_file=False
                )
                
                if metadata2['success']:
                    print(f"âœ… Process2è·å–æˆåŠŸ:")
                    print(f"   tabåŒ¹é…: {metadata2.get('tab_id') == result.get('tab_id')}")
                    print(f"   åŸå­æ•°: {metadata2.get('atoms')}")
                else:
                    print(f"âŒ Process2è·å–å¤±è´¥")
            else:
                print(f"âŒ Process1å¤„ç†ç»“æœå­˜å‚¨å¤±è´¥")
        else:
            print(f"âŒ Process1è·å–å¤±è´¥")
        
        print("\nğŸ¯ æ­¥éª¤5: æœ€ç»ˆç¼“å­˜çŠ¶æ€")
        print("-" * 40)
        
        final_cache = get_cache_status()
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {final_cache['total_nodes']}")
        
        # æŒ‰tab_idåˆ†ç»„æ˜¾ç¤º
        from collections import defaultdict
        by_tab = defaultdict(list)
        
        for node in final_cache['nodes']:
            tab_id = node['tab_id'] or 'unknown'
            by_tab[tab_id].append(node)
        
        for tab_id, nodes in by_tab.items():
            print(f"\nğŸ“‚ Tab: {tab_id}")
            for node in nodes:
                print(f"   â””â”€ {node['node_id']} | {node['filename']} | {node['atoms']} atoms")
        
        print("\nâœ… Tabæ„ŸçŸ¥å†…å­˜ç®¡ç†æµ‹è¯•å®Œæˆ!")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def test_frontend_hash_mechanism():
    """æµ‹è¯•å‰ç«¯hashæœºåˆ¶ç®€åŒ–"""
    print("\nğŸ”§ å‰ç«¯Hashæœºåˆ¶æµ‹è¯•")
    print("=" * 40)
    
    # æ¨¡æ‹Ÿå‰ç«¯ç”Ÿæˆnode_idçš„æ–°é€»è¾‘
    def generate_simple_node_id(tab_id, node_id):
        """æ¨¡æ‹Ÿç®€åŒ–çš„å‰ç«¯node_idç”Ÿæˆ"""
        return f"{tab_id}_node_{node_id}"
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("workflow_abc12", 23),
        ("workflow_def34", 45),
        ("workflow_gh567", 89),
    ]
    
    print("ğŸ†” æ–°çš„ç®€åŒ–IDç”Ÿæˆ:")
    for tab_id, node_id in test_cases:
        simple_id = generate_simple_node_id(tab_id, node_id)
        print(f"   {tab_id} + {node_id} = {simple_id}")
    
    print("\nâœ… å‰ç«¯Hashæœºåˆ¶ç®€åŒ–æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ALCHEM_PropBtn Tabæ„ŸçŸ¥è°ƒè¯•")
    test_tab_aware_memory()
    test_frontend_hash_mechanism()
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")